{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation from original file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sheet names: \n",
    "- 'App - Usage Time'\n",
    "- 'App - Usage Count'\n",
    "- 'Web - Usage Time'\n",
    "- 'Web - Usage Count'\n",
    "- 'Device Unlocks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Device</th>\n",
       "      <th>October 28, 2022</th>\n",
       "      <th>October 29, 2022</th>\n",
       "      <th>October 30, 2022</th>\n",
       "      <th>October 31, 2022</th>\n",
       "      <th>November 1, 2022</th>\n",
       "      <th>November 2, 2022</th>\n",
       "      <th>November 3, 2022</th>\n",
       "      <th>November 4, 2022</th>\n",
       "      <th>...</th>\n",
       "      <th>June 16, 2023</th>\n",
       "      <th>June 17, 2023</th>\n",
       "      <th>June 18, 2023</th>\n",
       "      <th>June 19, 2023</th>\n",
       "      <th>June 20, 2023</th>\n",
       "      <th>June 21, 2023</th>\n",
       "      <th>June 22, 2023</th>\n",
       "      <th>June 23, 2023</th>\n",
       "      <th>June 24, 2023</th>\n",
       "      <th>Total Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001.tl</td>\n",
       "      <td>motorola moto g(6) plus</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>...</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>1s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001tracklists.com</td>\n",
       "      <td>motorola moto g(6) plus</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>...</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>27s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100daysofcode.com</td>\n",
       "      <td>motorola moto g(6) plus</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>...</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>0s</td>\n",
       "      <td>12s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Device October 28, 2022  \\\n",
       "0             1001.tl  motorola moto g(6) plus               0s   \n",
       "1  1001tracklists.com  motorola moto g(6) plus               0s   \n",
       "2   100daysofcode.com  motorola moto g(6) plus               0s   \n",
       "\n",
       "  October 29, 2022 October 30, 2022 October 31, 2022 November 1, 2022  \\\n",
       "0               0s               0s               0s               0s   \n",
       "1               0s               0s               0s               0s   \n",
       "2               0s               0s               0s               0s   \n",
       "\n",
       "  November 2, 2022 November 3, 2022 November 4, 2022  ... June 16, 2023  \\\n",
       "0               0s               0s               0s  ...            0s   \n",
       "1               0s               0s               0s  ...            0s   \n",
       "2               0s               0s               0s  ...            0s   \n",
       "\n",
       "  June 17, 2023 June 18, 2023 June 19, 2023 June 20, 2023 June 21, 2023  \\\n",
       "0            0s            0s            0s            0s            0s   \n",
       "1            0s            0s            0s            0s            0s   \n",
       "2            0s            0s            0s            0s            0s   \n",
       "\n",
       "  June 22, 2023 June 23, 2023 June 24, 2023 Total Usage  \n",
       "0            0s            0s            0s          1s  \n",
       "1            0s            0s            0s         27s  \n",
       "2            0s            0s            0s         12s  \n",
       "\n",
       "[3 rows x 243 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_excel('D:/Estiven/Datos/Proyectos/statistics-of-use-project/data/raw/StayFree Export - Total Usage - 6_24_23 (1).xls',\n",
    "                         sheet_name='Web - Usage Time').rename({'Unnamed: 0': ''}, axis=1)\n",
    "raw_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three groups will be given by the groupby function: \n",
    "- 'Windows Extensión para Chrome'\n",
    "- 'Windows Extensión para Edge'\n",
    "- 'motorola moto g(6) plus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sheet names: \n",
    "- 'App - Usage Time'\n",
    "- 'App - Usage Count'\n",
    "- 'Web - Usage Time'\n",
    "- 'Web - Usage Count'\n",
    "- 'Device Unlocks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in filename\n"
     ]
    }
   ],
   "source": [
    "filename = 'Web - Usage Time'\n",
    "if 'App' in filename:\n",
    "    print('Yes, in filename')\n",
    "elif 'App'\n",
    "else: print('Not in filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_excel_sheets(file_path):\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    sheet_names = xls.sheet_names\n",
    "\n",
    "    dataframes_dict = {}\n",
    "    \n",
    "    # Read each sheet and store it in the dictionary\n",
    "    for sheet_name in sheet_names:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name).rename({'Unnamed: 0': ''}, axis=1)\n",
    "        dataframes_dict[sheet_name] = df\n",
    "\n",
    "    sheet_names_list = list(dataframes_dict.keys())  \n",
    "    transformed_dataframes = {}\n",
    "\n",
    "    for sheet_name in sheet_names_list:\n",
    "        dataframe = dataframes_dict[sheet_name]\n",
    "\n",
    "        if 'Web' in sheet_name:\n",
    "            dataframe = dataframe.drop(columns=['Total Usage'])\n",
    "            dataframe = dataframe.iloc[:-4]\n",
    "            \n",
    "            grouped_data = dataframe.groupby('Device')\n",
    "\n",
    "            # Transformation of every dataframe in the groupby\n",
    "            for device, group in grouped_data:\n",
    "                # Transpose the dataframe\n",
    "                group = group.T\n",
    "                group.columns = group.iloc[0]\n",
    "\n",
    "                # Eliminating duplicated columns\n",
    "                duplicated_columns = group.columns[group.columns.duplicated()]\n",
    "                group = group.loc[:, ~group.columns.duplicated()]\n",
    "\n",
    "                # Drop the first row since it is now the header\n",
    "                group = group[1:].reset_index().rename({'index': 'date'}, axis=1)\n",
    "                group = group.iloc[1:]\n",
    "\n",
    "                if 'Time' in sheet_name:\n",
    "                # Time transformation to minutes, (code made in main_notebook_data_transformation notebook)\n",
    "                    for col in group.columns:\n",
    "                        if col != 'date':\n",
    "                            group[col] = round(pd.to_timedelta(group[col]).dt.total_seconds() / 60, 2)\n",
    "                        else:\n",
    "                            pass\n",
    "                sheet_name_appropiate = sheet_name.lower() \\\n",
    "                                                  .replace('-', '') \\\n",
    "                                                  .replace('  ', ' ') \\\n",
    "                                                  .replace(' ', '_')\n",
    "                device_name_appropiate = device.split(' ')[-1]\n",
    "                transformed_dataframes[f'{sheet_name_appropiate}_{device_name_appropiate}'] = group\n",
    "                        \n",
    "        elif ('App' in sheet_name) or ('Device' in sheet_name):\n",
    "            if 'Device' in dataframe.columns:\n",
    "                # If 'Device' column exists, drop both 'Total Usage' and 'Device'\n",
    "                dataframe = dataframe.drop(columns=['Total Usage', 'Device'])\n",
    "            else:\n",
    "                # If 'Device' column does not exist, only drop 'Total Usage'\n",
    "                dataframe = dataframe.drop(columns=['Total Usage'])\n",
    "\n",
    "            dataframe = dataframe.iloc[:-4]\n",
    "\n",
    "            dataframe = dataframe.T\n",
    "\n",
    "            dataframe.columns = dataframe.iloc[0]\n",
    "            duplicated_columns = dataframe.columns[dataframe.columns.duplicated()]\n",
    "            dataframe = dataframe.loc[:, ~dataframe.columns.duplicated()]\n",
    "\n",
    "            dataframe = dataframe[1:].reset_index().rename({'index': 'date'}, axis=1)\n",
    "\n",
    "            # Time transformation to minutes, (only time data, not count data)\n",
    "            for col in dataframe.columns:\n",
    "                if col != 'date':\n",
    "                    dataframe[col] = round(pd.to_timedelta(dataframe[col]).dt.total_seconds() / 60, 2)\n",
    "                else: pass\n",
    "\n",
    "            sheet_name_appropiate = sheet_name.lower() \\\n",
    "                                              .replace('-', '') \\\n",
    "                                              .replace('  ', ' ') \\\n",
    "                                              .replace(' ', '_')\n",
    "            transformed_dataframes[sheet_name_appropiate] = dataframe\n",
    "\n",
    "    return transformed_dataframes\n",
    "\n",
    "excel_file_path = \"D:/Estiven/Datos/Proyectos/statistics-of-use-project/data/raw/StayFree Export - Total Usage - 6_24_23 (1).xls\"\n",
    "transformed = read_excel_sheets(excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_excel_sheets(file_path):\n",
    "    \"\"\"\n",
    "    Read different sheets of an Excel file into separate dataframes and apply specific transformations.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The path to the Excel file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the transformed dataframes for each sheet.\n",
    "    \"\"\"\n",
    "    \n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    sheet_names = xls.sheet_names\n",
    "\n",
    "    # Create a dictionary to store the dataframes for each sheet\n",
    "    dataframes_dict = {}\n",
    "    \n",
    "    # Read each sheet and store it in the dictionary\n",
    "    for sheet_name in sheet_names:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name).rename({'Unnamed: 0': ''}, axis=1)\n",
    "        dataframes_dict[sheet_name] = df\n",
    "\n",
    "    # Get a list of sheet names from the dictionary\n",
    "    sheet_names_list = list(dataframes_dict.keys())  \n",
    "    \n",
    "    transformed_dataframes = {}\n",
    "\n",
    "    # Process each sheet\n",
    "    for sheet_name in sheet_names_list:\n",
    "        dataframe = dataframes_dict[sheet_name]\n",
    "\n",
    "        if 'Web' in sheet_name:\n",
    "            # Drop the 'Total Usage' column and remove the last 4 rows\n",
    "            dataframe = dataframe.drop(columns=['Total Usage'])\n",
    "            dataframe = dataframe.iloc[:-4]\n",
    "            \n",
    "            grouped_data = dataframe.groupby('Device')\n",
    "\n",
    "            # Transformation of every dataframe in the groupby\n",
    "            for device, group in grouped_data:\n",
    "                # Transpose the dataframe and set the first row as column headers\n",
    "                group = group.T\n",
    "                group.columns = group.iloc[0]\n",
    "\n",
    "                # Eliminate duplicated columns in the dataframe\n",
    "                duplicated_columns = group.columns[group.columns.duplicated()]\n",
    "                group = group.loc[:, ~group.columns.duplicated()]\n",
    "\n",
    "                # Drop the first row since it is now the header\n",
    "                group = group[1:].reset_index().rename({'index': 'date'}, axis=1)\n",
    "                group = group.iloc[1:]\n",
    "\n",
    "                if 'Time' in sheet_name:\n",
    "                    # Time transformation to minutes (code made in main_notebook_data_transformation notebook)\n",
    "                    for col in group.columns:\n",
    "                        if col != 'date':\n",
    "                            group[col] = round(pd.to_timedelta(group[col]).dt.total_seconds() / 60, 2)\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "                # Format the sheet name and device name for the transformed dataframe's key\n",
    "                sheet_name_appropriate = sheet_name.lower() \\\n",
    "                                                  .replace('-', '') \\\n",
    "                                                  .replace('  ', ' ') \\\n",
    "                                                  .replace(' ', '_')\n",
    "                \n",
    "                device_name_appropriate = device.split(' ')[-1]\n",
    "                # Store the transformed dataframe in the final dictionary\n",
    "                transformed_dataframes[f'{sheet_name_appropriate}_{device_name_appropriate}'] = group\n",
    "                        \n",
    "        # For sheets containing 'App' or 'Device', perform different transformations\n",
    "        elif ('App' in sheet_name) or ('Device' in sheet_name):\n",
    "            if 'Device' in dataframe.columns:\n",
    "                # If 'Device' column exists, drop both 'Total Usage' and 'Device'\n",
    "                dataframe = dataframe.drop(columns=['Total Usage', 'Device'])\n",
    "            else:\n",
    "                # If 'Device' column does not exist, only drop 'Total Usage'\n",
    "                dataframe = dataframe.drop(columns=['Total Usage'])\n",
    "\n",
    "            dataframe = dataframe.iloc[:-4].T\n",
    "            dataframe.columns = dataframe.iloc[0]\n",
    "\n",
    "            duplicated_columns = dataframe.columns[dataframe.columns.duplicated()]\n",
    "            dataframe = dataframe.loc[:, ~dataframe.columns.duplicated()]\n",
    "\n",
    "            dataframe = dataframe[1:].reset_index().rename({'index': 'date'}, axis=1)\n",
    "\n",
    "            # Time transformation to minutes, only for time data, not count data\n",
    "            if 'Time' in sheet_name:\n",
    "                \n",
    "                for col in dataframe.columns:\n",
    "                    if col != 'date':\n",
    "                        dataframe[col] = round(pd.to_timedelta(dataframe[col]).dt.total_seconds() / 60, 2)\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "            sheet_name_appropriate = sheet_name.lower() \\\n",
    "                                              .replace('-', '') \\\n",
    "                                              .replace('  ', ' ') \\\n",
    "                                              .replace(' ', '_')\n",
    "            transformed_dataframes[sheet_name_appropriate + '_motorola'] = dataframe\n",
    "\n",
    "    # Format the sheet names for the transformed dataframe's key\n",
    "    final_data = {key.lower().replace('plus', 'motorola'): value for key, value in transformed_dataframes.items()}\n",
    "    return final_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace the file_path with the actual path to your Excel file\n",
    "    excel_file_path = \"D:/Estiven/Datos/Proyectos/statistics-of-use-project/data/raw/StayFree Export - Total Usage - 6_24_23 (1).xls\"\n",
    "    transformed = read_excel_sheets(excel_file_path)\n",
    "\n",
    "    # Save the dataframes into csv files\n",
    "    path_final_files = \"D:/Estiven/Datos/Proyectos/statistics-of-use-project/data/\"\n",
    "    for key, values in transformed.items():\n",
    "        values.to_csv(path_final_files + key + '.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['app_usage_time', 'app_usage_count', 'web_usage_time_chrome', 'web_usage_time_edge', 'web_usage_time_motorola', 'web_usage_count_chrome', 'web_usage_count_edge', 'web_usage_count_motorola', 'device_unlocks'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "raw_data = raw_data.drop(columns=['Total Usage'])\n",
    "\n",
    "# Eliminate the last 4 rows of the data\n",
    "raw_data = raw_data.iloc[:-4]\n",
    "\n",
    "grouped_data = raw_data.groupby('Device')\n",
    "transformed_dataframes = {}\n",
    "\n",
    "# Transformation of every dataframe in the groupby\n",
    "for device, group in grouped_data:\n",
    "    # Transpose the dataframe\n",
    "    group = group.T\n",
    "    group.columns = group.iloc[0]\n",
    "\n",
    "    # Eliminating duplicated columns\n",
    "    duplicated_columns = group.columns[group.columns.duplicated()]\n",
    "    group = group.loc[:, ~group.columns.duplicated()]\n",
    "\n",
    "    # Drop the first row since it is now the header\n",
    "    group = group[1:].reset_index().rename({'index': 'date'}, axis=1)\n",
    "    group = group.iloc[1:]\n",
    "\n",
    "    # Time transformation to minutes, (code made in main_notebook_data_transformation notebook)\n",
    "    for col in group.columns:\n",
    "        if col != 'date':\n",
    "            group[col] = round(pd.to_timedelta(group[col]).dt.total_seconds() / 60, 2)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    transformed_dataframes[device] = group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "App files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecesary columns\n",
    "raw_data = raw_data.drop(columns=['Total Usage', 'Device'])\n",
    "\n",
    "# Eliminate the last 4 rows of the data\n",
    "raw_data = raw_data.iloc[:-4]\n",
    "\n",
    "# Transpose the dataframe\n",
    "raw_data = raw_data.T\n",
    "\n",
    "# Set the first row as column names\n",
    "raw_data.columns = raw_data.iloc[0]\n",
    "\n",
    "# Eliminating duplicated columns\n",
    "duplicated_columns = raw_data.columns[raw_data.columns.duplicated()]\n",
    "raw_data = raw_data.loc[:, ~raw_data.columns.duplicated()]\n",
    "\n",
    "# Drop the first row since it is now the header\n",
    "raw_data = raw_data[1:].reset_index().rename({'index': 'date'}, axis=1)\n",
    "\n",
    "# Time transformation to minutes, (only time data, not count data)\n",
    "for col in raw_data.columns:\n",
    "    if col != 'date':\n",
    "        raw_data[col] = round(pd.to_timedelta(raw_data[col]).dt.total_seconds() / 60, 2)\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>udea.edu.co</th>\n",
       "      <th>chat.openai.com</th>\n",
       "      <th>tiktok.com</th>\n",
       "      <th>vm.tiktok.com</th>\n",
       "      <th>openai.com</th>\n",
       "      <th>google.com</th>\n",
       "      <th>instagram.com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  udea.edu.co  chat.openai.com  tiktok.com  vm.tiktok.com  \\\n",
       "0 2022-10-28            2                0           2              2   \n",
       "1 2022-10-30            1                0          10              3   \n",
       "\n",
       "   openai.com  google.com  instagram.com  \n",
       "0           0          12              0  \n",
       "1           0           5              0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('D:/Estiven/Datos/Proyectos/statistics-of-use-project/data/processed/web_usage_count_motorola.csv',\n",
    "                   delimiter=';',\n",
    "                   parse_dates=['date'])\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to filter the dataframe based on the values we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataframe(dataframe: pd.DataFrame, values_greater_than):\n",
    "    data_copy = dataframe.copy()\n",
    "\n",
    "    #packing the name of columns and sums in a dictionary to use in further codes\n",
    "    dictionary_sums = {}\n",
    "    for column in data_copy:\n",
    "        if (column != 'date') and \\\n",
    "           (sum(data_copy[column]) >= values_greater_than):\n",
    "            \n",
    "            dictionary_sums[column] = sum(data_copy[column])\n",
    "\n",
    "    names_of_columns_to_stay = [column_name for column_name in dictionary_sums.keys()]\n",
    "    names_of_columns_to_stay.insert(0, 'date')\n",
    "\n",
    "    #filtering dataframe\n",
    "    transformed_dataframe = data_copy[names_of_columns_to_stay]\n",
    "    \n",
    "    return transformed_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation of the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.gitkeep',\n",
       " 'app_usage_count_motorola.csv',\n",
       " 'app_usage_time_motorola.csv',\n",
       " 'device_unlocks.csv',\n",
       " 'web_usage_count_chrome.csv',\n",
       " 'web_usage_count_edge.csv',\n",
       " 'web_usage_count_motorola.csv',\n",
       " 'web_usage_time_chrome.csv',\n",
       " 'web_usage_time_edge.csv',\n",
       " 'web_usage_time_motorola.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"D:/Estiven/Datos/Proyectos/statistics-of-use-project/data/processed\"\n",
    "dir_list = listdir(path)\n",
    "dir_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to transform files with a specified word in it, replace it in the fist line of the code.\n",
    "- For \"count\" files, the delimiter should be changed to \";\"\n",
    "- For \"time\" files, the delimiter should be changed to \",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_find = \"count\" # word in the name of the file that you want to search for\n",
    "for file in dir_list:\n",
    "    word_is_in = re.search(word_to_find, file)\n",
    "    if word_is_in:\n",
    "        file_path = f'D:/Estiven/Datos/Proyectos/statistics-of-use-project/data/processed/{file}'\n",
    "        data = pd.read_csv(file_path,\n",
    "                           delimiter=';',\n",
    "                           parse_dates=['date'])\n",
    "        \n",
    "        data_transformed = transform_dataframe(data, 100)\n",
    "        data_transformed = data_transformed.set_index('date')\n",
    "        data_transformed.sort_values(by='date', ascending=True, inplace=True)\n",
    "        data_transformed = data_transformed[~data_transformed.duplicated()]\n",
    "        data_transformed = data_transformed.reset_index()\n",
    "\n",
    "        export_path = f'D:/Estiven/Datos/Proyectos/statistics-of-use-project/data/processed/{file}'\n",
    "        data_transformed.to_csv(export_path, \n",
    "                                sep=';',\n",
    "                                index=None,\n",
    "                                date_format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation to 'device_unlocks.csv' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12776\\77304124.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data = pd.read_csv(file_path,\n"
     ]
    }
   ],
   "source": [
    "file_path = f'D:/Estiven/Datos/Proyectos/statistics-of-use-project/data/processed/device_unlocks.csv'\n",
    "data = pd.read_csv(file_path,\n",
    "                   delimiter=';',\n",
    "                   parse_dates=['date'])\n",
    "\n",
    "export_path = f'D:/Estiven/Datos/Proyectos/statistics-of-use-project/data/processed/device_unlocks.csv'\n",
    "data.to_csv(export_path, \n",
    "                        sep=';',\n",
    "                        index=None,\n",
    "                        date_format='%Y-%m-%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statistics_of_use_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
